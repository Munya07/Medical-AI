{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport random \nfrom tqdm import tqdm\n\nimport os\nimport keras\nimport pydicom\n\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef read_pickle(filename):    \n    with open(filename, 'rb') as fp:\n        return pickle.load(fp)\n    \ndef save_pickle(data,filename):       \n    with open(filename, 'wb') as fp:\n        pickle.dump(data, fp)  \n    \ndata_path = '../input/rsna-pneumonia-detection-challenge/'\n\nimages_path = data_path + 'stage_2_train_images/'\nlabels_path = data_path + 'stage_2_train_labels.csv'\n\ndetailed_class_info_path = data_path + 'stage_2_detailed_class_info.csv'\n\nclass_encoder = LabelEncoder()\n   \ndef merge_dataframes():\n    df = pd.read_csv(labels_path)\n    details_df = pd.read_csv(detailed_class_info_path)\n    df = pd.concat([df,details_df.drop('patientId',1)], 1) \n    print(df.describe())\n    print(df.shape[0], 'cases')\n\n    return df\n\n\n  \ndef load_ids_and_labels_from_file():\n    ids = read_pickle('ids')\n    labels = read_pickle('labels')\n    return ids,labels\n  \ndef get_ids_and_labels(num_class):\n    df = merge_dataframes()\n    df['class_id'] = class_encoder.fit_transform(df['class'])\n\n    df.sort_values(by=['patientId', 'class_id'])\n    \n    ids = df.patientId.tolist()\n    \n    if(num_class==2):\n        labels =  df.Target.tolist() \n    else:\n        labels =  df.class_id.tolist() \n    \n    save_pickle(ids, 'ids')\n    save_pickle(labels, 'labels')\n\n    return ids,labels\n\n      \n\nnum_class = 3\nids,labels = get_ids_and_labels(num_class)\n\n",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 x            y      ...            height        Target\ncount  9555.000000  9555.000000      ...       9555.000000  30227.000000\nmean    394.047724   366.839560      ...        329.269702      0.316108\nstd     204.574172   148.940488      ...        157.750755      0.464963\nmin       2.000000     2.000000      ...         45.000000      0.000000\n25%     207.000000   249.000000      ...        203.000000      0.000000\n50%     324.000000   365.000000      ...        298.000000      0.000000\n75%     594.000000   478.500000      ...        438.000000      1.000000\nmax     835.000000   881.000000      ...        942.000000      1.000000\n\n[8 rows x 5 columns]\n30227 cases\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b9dfd9373721dda272c1954a7213a16e772e874"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nfeature_tensors = np.load('../input/inception/inception_resnet_v2_features.npz')['arr_0']\n\n\ny = labels[:feature_tensors.shape[0]]\n\nX_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.1, random_state=42)\n",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\nimport matplotlib.pyplot as plt\n\n\ndef precision_recall(name, clf):  \n    y_pred = clf.predict(X_test)\n    \n    if(num_class==2):\n        roc_score = roc_auc_score(y_test, y_pred)\n        print('roc_auc_score', roc_score)\n\n    \n    if(num_class==3):\n        report = classification_report(y_test, y_pred, target_names=class_encoder.classes_)\n    else:\n        report = classification_report(y_test, y_pred)\n        \n    print('classification report for', name)\n    print( report )\n    \n\ndef evaluate_classifier(clf,name):    \n    clf.fit(X_train,y_train)\n\n    save_pickle(clf,name)\n\n    precision_recall(name, clf)\n    \n    score = clf.score(X_test,y_test)\n    \n    print('average_score', round(score,3))",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13192e4fd1672752b4bf629a3db50e207b7597f9"
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\nname = 'DecisionTreeClassifier'\nevaluate_classifier(clf,name)     ",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for DecisionTreeClassifier\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.63      0.76      0.69       987\nNo Lung Opacity / Not Normal       0.49      0.44      0.46      1136\n                      Normal       0.41      0.37      0.39       898\n\n                   micro avg       0.52      0.52      0.52      3021\n                   macro avg       0.51      0.52      0.51      3021\n                weighted avg       0.51      0.52      0.51      3021\n\naverage_score 0.523\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7ebce66390c6b9a0e1ba760ed88ca671252a040"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclf = LinearDiscriminantAnalysis()\n\nname = 'LinearDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for LinearDiscriminantAnalysis\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.56      0.53      0.55       987\nNo Lung Opacity / Not Normal       0.42      0.45      0.43      1136\n                      Normal       0.48      0.45      0.47       898\n\n                   micro avg       0.48      0.48      0.48      3021\n                   macro avg       0.49      0.48      0.48      3021\n                weighted avg       0.48      0.48      0.48      3021\n\naverage_score 0.479\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c2e061452e769abbe4c3f7c868afb2e6058b70d"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclf = QuadraticDiscriminantAnalysis()\n\nname = 'QuadraticDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for QuadraticDiscriminantAnalysis\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.65      0.72      0.68       987\nNo Lung Opacity / Not Normal       0.49      0.42      0.45      1136\n                      Normal       0.49      0.52      0.50       898\n\n                   micro avg       0.55      0.55      0.55      3021\n                   macro avg       0.54      0.55      0.55      3021\n                weighted avg       0.54      0.55      0.54      3021\n\naverage_score 0.548\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cdf1d3115ec16d1589287aed532854b06e7b5678"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n\nname = 'RandomForestClassifier'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "classification report for RandomForestClassifier\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.62      0.75      0.68       987\nNo Lung Opacity / Not Normal       0.47      0.49      0.48      1136\n                      Normal       0.47      0.34      0.39       898\n\n                   micro avg       0.53      0.53      0.53      3021\n                   macro avg       0.52      0.53      0.52      3021\n                weighted avg       0.52      0.53      0.52      3021\n\naverage_score 0.53\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "136a3c09d212d209e8e4a010fc602188c40af269"
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\n\nname = 'GaussianNB'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for GaussianNB\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.45      0.56      0.50       987\nNo Lung Opacity / Not Normal       0.49      0.10      0.16      1136\n                      Normal       0.38      0.67      0.49       898\n\n                   micro avg       0.42      0.42      0.42      3021\n                   macro avg       0.44      0.44      0.38      3021\n                weighted avg       0.45      0.42      0.37      3021\n\naverage_score 0.418\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4cffbe582e7f63df6a65bb5b2446e8c9c8f5963"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import LinearSVC\n\nclf = LinearSVC()\nname = 'LinearSVC'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for LinearSVC\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.54      0.56      0.55       987\nNo Lung Opacity / Not Normal       0.41      0.42      0.41      1136\n                      Normal       0.48      0.44      0.46       898\n\n                   micro avg       0.47      0.47      0.47      3021\n                   macro avg       0.48      0.47      0.47      3021\n                weighted avg       0.47      0.47      0.47      3021\n\naverage_score 0.472\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47057d10c63c2ab1b6c5649f104b272910e110af"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f699e5ac76998dc35ca98c7ec5379bb4b4b9ce3e"
      },
      "cell_type": "code",
      "source": "\nfrom sklearn.model_selection import train_test_split\n\ny = labels[:feature_tensors.shape[0]]\ny = np.array(y)\ny = keras.utils.to_categorical(y, num_class)\n\nX_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Dense, Flatten,BatchNormalization,LeakyReLU\nfrom keras.metrics import categorical_accuracy, binary_accuracy\n\nif(num_class==2):\n    print(2)\n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[binary_accuracy])\n\nelse:\n    print(3)\n\n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[categorical_accuracy])\n\n\n\nmodel.fit(X_train,y_train,\n          epochs=12,\n          batch_size=16,\n          validation_data=(X_test, y_test)\n         )\n\nmodel.save('inception.h5') ",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "3\nTrain on 24166 samples, validate on 6042 samples\nEpoch 1/12\n24166/24166 [==============================] - 7s 294us/step - loss: 1.0717 - categorical_accuracy: 0.4069 - val_loss: 1.0408 - val_categorical_accuracy: 0.4346\nEpoch 2/12\n24166/24166 [==============================] - 6s 238us/step - loss: 1.0448 - categorical_accuracy: 0.4304 - val_loss: 1.0295 - val_categorical_accuracy: 0.4416\nEpoch 3/12\n24166/24166 [==============================] - 6s 230us/step - loss: 1.0410 - categorical_accuracy: 0.4325 - val_loss: 1.0228 - val_categorical_accuracy: 0.4424\nEpoch 4/12\n24166/24166 [==============================] - 6s 233us/step - loss: 1.0375 - categorical_accuracy: 0.4337 - val_loss: 1.0346 - val_categorical_accuracy: 0.4500\nEpoch 5/12\n24166/24166 [==============================] - 6s 229us/step - loss: 1.0362 - categorical_accuracy: 0.4363 - val_loss: 1.0351 - val_categorical_accuracy: 0.4568\nEpoch 6/12\n24166/24166 [==============================] - 6s 239us/step - loss: 1.0347 - categorical_accuracy: 0.4407 - val_loss: 1.0195 - val_categorical_accuracy: 0.4431\nEpoch 7/12\n24166/24166 [==============================] - 6s 243us/step - loss: 1.0333 - categorical_accuracy: 0.4438 - val_loss: 1.0307 - val_categorical_accuracy: 0.4295\nEpoch 8/12\n24166/24166 [==============================] - 6s 234us/step - loss: 1.0308 - categorical_accuracy: 0.4473 - val_loss: 1.0189 - val_categorical_accuracy: 0.4465\nEpoch 9/12\n24166/24166 [==============================] - 6s 237us/step - loss: 1.0289 - categorical_accuracy: 0.4458 - val_loss: 1.0281 - val_categorical_accuracy: 0.4464\nEpoch 10/12\n24166/24166 [==============================] - 6s 228us/step - loss: 1.0290 - categorical_accuracy: 0.4474 - val_loss: 1.0197 - val_categorical_accuracy: 0.4586\nEpoch 11/12\n24166/24166 [==============================] - 6s 231us/step - loss: 1.0279 - categorical_accuracy: 0.4500 - val_loss: 1.0243 - val_categorical_accuracy: 0.4335\nEpoch 12/12\n24166/24166 [==============================] - 5s 226us/step - loss: 1.0316 - categorical_accuracy: 0.4405 - val_loss: 1.0171 - val_categorical_accuracy: 0.4512\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "50a474294bc79e34d1cd99f2bcacb7f00c11bc81"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}