{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54d53ad6824b56d6621db7c7fe47a857f6d05d90"
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport random \nfrom tqdm import tqdm\n\nimport os\nimport keras\nimport pydicom\n\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef read_pickle(filename):    \n    with open(filename, 'rb') as fp:\n        return pickle.load(fp)\n    \ndef save_pickle(data,filename):       \n    with open(filename, 'wb') as fp:\n        pickle.dump(data, fp)  \n    \ndata_path = '../input/' # rsna-pneumonia-detection-challenge/\n\nimages_path = data_path + 'stage_2_train_images/'\nlabels_path = data_path + 'stage_2_train_labels.csv'\n\ndetailed_class_info_path = data_path + 'stage_2_detailed_class_info.csv'\n\nclass_encoder = LabelEncoder()\n   \ndef merge_dataframes():\n    df = pd.read_csv(labels_path)\n    details_df = pd.read_csv(detailed_class_info_path)\n    df = pd.concat([df,details_df.drop('patientId',1)], 1) \n    print(df.describe())\n    print(df.shape[0], 'cases')\n\n    return df\n\n\n  \ndef load_ids_and_labels_from_file():\n    ids = read_pickle('ids')\n    labels = read_pickle('labels')\n    return ids,labels\n  \ndef get_ids_and_labels(num_class):\n    df = merge_dataframes()\n    df['class_id'] = class_encoder.fit_transform(df['class'])\n\n    df.sort_values(by=['patientId', 'class_id'])\n    \n    ids = df.patientId.tolist()\n    \n    if(num_class==2):\n        labels =  df.Target.tolist() \n    else:\n        labels =  df.class_id.tolist() \n    \n    save_pickle(ids, 'ids')\n    save_pickle(labels, 'labels')\n\n    return ids,labels\n\n      \n\nnum_class = 2\nids,labels = get_ids_and_labels(num_class)\n",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 x            y      ...            height        Target\ncount  9555.000000  9555.000000      ...       9555.000000  30227.000000\nmean    394.047724   366.839560      ...        329.269702      0.316108\nstd     204.574172   148.940488      ...        157.750755      0.464963\nmin       2.000000     2.000000      ...         45.000000      0.000000\n25%     207.000000   249.000000      ...        203.000000      0.000000\n50%     324.000000   365.000000      ...        298.000000      0.000000\n75%     594.000000   478.500000      ...        438.000000      1.000000\nmax     835.000000   881.000000      ...        942.000000      1.000000\n\n[8 rows x 5 columns]\n30227 cases\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32185f36bb775a0b02edf485f04b05a3a74e47a3"
      },
      "cell_type": "code",
      "source": "feature_tensors = np.load('vgg16_features.npz')['arr_0']\n",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfc9bb73d76dcfb3be56c7ac17159515733f4215"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\ny = labels[:feature_tensors.shape[0]]\n\nX_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47926695fa8f471f430dfe54a65f7046454c0c75"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\nimport matplotlib.pyplot as plt\n\n\ndef precision_recall(name, clf):  \n    y_pred = clf.predict(X_test)\n    \n    if(num_class==2):\n        roc_score = roc_auc_score(y_test, y_pred)\n        print('roc_auc_score', roc_score)\n\n    \n    if(num_class==3):\n        report = classification_report(y_test, y_pred, target_names=class_encoder.classes_)\n    else:\n        report = classification_report(y_test, y_pred)\n        \n    print('classification report for', name)\n    print( report )\n    \n\ndef evaluate_classifier(clf,name):    \n    clf.fit(X_train,y_train)\n\n    save_pickle(clf,name)\n\n    precision_recall(name, clf)\n    \n    score = clf.score(X_test,y_test)\n    \n    print('average_score', round(score,3))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d0434758026deaa2d559d611bba0e6f11900224"
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\nname = 'DecisionTreeClassifier'\nevaluate_classifier(clf,name)     ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.7507587036619295\nclassification report for DecisionTreeClassifier\n              precision    recall  f1-score   support\n\n           0       0.86      0.77      0.81      4092\n           1       0.60      0.73      0.66      1950\n\n   micro avg       0.76      0.76      0.76      6042\n   macro avg       0.73      0.75      0.74      6042\nweighted avg       0.78      0.76      0.76      6042\n\naverage_score 0.758\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c40c74d5fdebd1783fa29760c34fdcc2ea392c71"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n\nname = 'RandomForestClassifier'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.7751278291600873\nclassification report for RandomForestClassifier\n              precision    recall  f1-score   support\n\n           0       0.84      0.93      0.88      4092\n           1       0.81      0.62      0.70      1950\n\n   micro avg       0.83      0.83      0.83      6042\n   macro avg       0.82      0.78      0.79      6042\nweighted avg       0.83      0.83      0.82      6042\n\naverage_score 0.831\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35a058475a05cd96e53c28e5ae69001706b2a234"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclf = LinearDiscriminantAnalysis()\n\nname = 'LinearDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) \n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclf = QuadraticDiscriminantAnalysis()\n\nname = 'QuadraticDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.6076768929994736\nclassification report for LinearDiscriminantAnalysis\n              precision    recall  f1-score   support\n\n           0       0.73      0.89      0.81      4092\n           1       0.59      0.32      0.42      1950\n\n   micro avg       0.71      0.71      0.71      6042\n   macro avg       0.66      0.61      0.61      6042\nweighted avg       0.69      0.71      0.68      6042\n\naverage_score 0.708\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.5091920445146252\nclassification report for QuadraticDiscriminantAnalysis\n              precision    recall  f1-score   support\n\n           0       0.86      0.03      0.05      4092\n           1       0.33      0.99      0.49      1950\n\n   micro avg       0.34      0.34      0.34      6042\n   macro avg       0.59      0.51      0.27      6042\nweighted avg       0.69      0.34      0.19      6042\n\naverage_score 0.338\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fbb66ef5b4b235bd323bfec1094cc955fc7a247"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import LinearSVC\n\nclf = LinearSVC()\nname = 'LinearSVC'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.5836318520189487\nclassification report for LinearSVC\n              precision    recall  f1-score   support\n\n           0       0.72      0.91      0.81      4092\n           1       0.59      0.25      0.35      1950\n\n   micro avg       0.70      0.70      0.70      6042\n   macro avg       0.65      0.58      0.58      6042\nweighted avg       0.68      0.70      0.66      6042\n\naverage_score 0.701\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fccc5a15fd0250266d93dcc5dad56e92b6aea2d1"
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\n\nname = 'GaussianNB'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.5664775547033611\nclassification report for GaussianNB\n              precision    recall  f1-score   support\n\n           0       0.72      0.78      0.75      4092\n           1       0.43      0.35      0.39      1950\n\n   micro avg       0.64      0.64      0.64      6042\n   macro avg       0.58      0.57      0.57      6042\nweighted avg       0.63      0.64      0.63      6042\n\naverage_score 0.643\nroc_auc_score 0.5093382961124897\nclassification report for Dummy stratified\n              precision    recall  f1-score   support\n\n           0       0.68      0.69      0.69      4092\n           1       0.34      0.33      0.33      1950\n\n   micro avg       0.57      0.57      0.57      6042\n   macro avg       0.51      0.51      0.51      6042\nweighted avg       0.57      0.57      0.57      6042\n\naverage_score 0.575\nroc_auc_score 0.5\nclassification report for Dummy prior\n              precision    recall  f1-score   support\n\n           0       0.68      1.00      0.81      4092\n           1       0.00      0.00      0.00      1950\n\n   micro avg       0.68      0.68      0.68      6042\n   macro avg       0.34      0.50      0.40      6042\nweighted avg       0.46      0.68      0.55      6042\n\naverage_score 0.677\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b94e9b995bd699fd0861a695cf9155eab1f51f7"
      },
      "cell_type": "code",
      "source": "num_class = 3\nids,labels = get_ids_and_labels(num_class)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 x            y      ...            height        Target\ncount  9555.000000  9555.000000      ...       9555.000000  30227.000000\nmean    394.047724   366.839560      ...        329.269702      0.316108\nstd     204.574172   148.940488      ...        157.750755      0.464963\nmin       2.000000     2.000000      ...         45.000000      0.000000\n25%     207.000000   249.000000      ...        203.000000      0.000000\n50%     324.000000   365.000000      ...        298.000000      0.000000\n75%     594.000000   478.500000      ...        438.000000      1.000000\nmax     835.000000   881.000000      ...        942.000000      1.000000\n\n[8 rows x 5 columns]\n30227 cases\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad11dcbe728938baadcb1fa3b16d8a6d0f370d7e"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dropout, Dense, Flatten,BatchNormalization,LeakyReLU\nfrom keras.metrics import categorical_accuracy, binary_accuracy\nimport keras\nfrom sklearn.model_selection import train_test_split\n\n\n\nif(num_class==2):\n    \n    y = labels[:feature_tensors.shape[0]]\n    y = np.array(y)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[binary_accuracy])\n\nelse:\n    y = labels[:feature_tensors.shape[0]]\n    y = keras.utils.to_categorical(y, num_class)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[categorical_accuracy])\n\n\n\nmodel.fit(X_train,y_train,\n          epochs=12,\n          batch_size=16,\n          validation_data=(X_test, y_test)\n         )\n\nmodel.save('vgg16' + num_class + 'class' + '.h5') ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eeb30cc719b6fb287e6ba155aae05fdcd6acec78"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6278836bb1f7184417e96f660e5414c8f61dbeb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02b09e09b46b20e1d5a78c29c40e0bae960b7c7a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}