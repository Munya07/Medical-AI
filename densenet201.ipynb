{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport random \nfrom tqdm import tqdm\n\nimport os\nimport keras\nimport pydicom\n\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef read_pickle(filename):    \n    with open(filename, 'rb') as fp:\n        return pickle.load(fp)\n    \ndef save_pickle(data,filename):       \n    with open(filename, 'wb') as fp:\n        pickle.dump(data, fp)  \n    \ndata_path = '../input/rsna-pneumonia-detection-challenge/'\n\nimages_path = data_path + 'stage_2_train_images/'\nlabels_path = data_path + 'stage_2_train_labels.csv'\n\ndetailed_class_info_path = data_path + 'stage_2_detailed_class_info.csv'\n\nclass_encoder = LabelEncoder()\n   \ndef merge_dataframes():\n    df = pd.read_csv(labels_path)\n    details_df = pd.read_csv(detailed_class_info_path)\n    df = pd.concat([df,details_df.drop('patientId',1)], 1) \n    print(df.describe())\n    print(df.shape[0], 'cases')\n\n    return df\n\n\n  \ndef load_ids_and_labels_from_file():\n    ids = read_pickle('ids')\n    labels = read_pickle('labels')\n    return ids,labels\n  \ndef get_ids_and_labels(num_class):\n    df = merge_dataframes()\n    df['class_id'] = class_encoder.fit_transform(df['class'])\n\n    df.sort_values(by=['patientId', 'class_id'])\n    \n    ids = df.patientId.tolist()\n    \n    if(num_class==2):\n        labels =  df.Target.tolist() \n    else:\n        labels =  df.class_id.tolist() \n    \n    save_pickle(ids, 'ids')\n    save_pickle(labels, 'labels')\n\n    return ids,labels\n\n      \n\nnum_class = 2\nids,labels = get_ids_and_labels(num_class)\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "                 x            y      ...            height        Target\ncount  9555.000000  9555.000000      ...       9555.000000  30227.000000\nmean    394.047724   366.839560      ...        329.269702      0.316108\nstd     204.574172   148.940488      ...        157.750755      0.464963\nmin       2.000000     2.000000      ...         45.000000      0.000000\n25%     207.000000   249.000000      ...        203.000000      0.000000\n50%     324.000000   365.000000      ...        298.000000      0.000000\n75%     594.000000   478.500000      ...        438.000000      1.000000\nmax     835.000000   881.000000      ...        942.000000      1.000000\n\n[8 rows x 5 columns]\n30227 cases\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a347c056f8fb0320df6a7a103aedd9067be63124"
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\n\nfeature_tensors = np.load('../input/densenet201/densenet201_features.npz')['arr_0']\n\n\nfrom sklearn.model_selection import train_test_split\n\ny = labels[:feature_tensors.shape[0]]\n\nX_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n\n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2132bedc5822e5bcf5108dece8a6faf37a68bc53"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\nimport matplotlib.pyplot as plt\n\n\ndef precision_recall(name, clf):  \n    y_pred = clf.predict(X_test)\n    \n    if(num_class==2):\n        roc_score = roc_auc_score(y_test, y_pred)\n        print('roc_auc_score', roc_score)\n\n    \n    if(num_class==3):\n        report = classification_report(y_test, y_pred, target_names=class_encoder.classes_)\n    else:\n        report = classification_report(y_test, y_pred)\n        \n    print('classification report for', name)\n    print( report )\n    \n\ndef evaluate_classifier(clf,name):    \n    clf.fit(X_train,y_train)\n\n    # save_pickle(clf,name)\n\n    precision_recall(name, clf)\n    \n    score = clf.score(X_test,y_test)\n    \n    print('average_score', round(score,3))",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2500565bbcb70b6f97f57c23f886bb1a8bfd9803"
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\n\nname = 'DecisionTreeClassifier'\n\nevaluate_classifier(clf,name) \n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.7525637265959846\nclassification report for DecisionTreeClassifier\n              precision    recall  f1-score   support\n\n           0       0.86      0.77      0.81      4092\n           1       0.60      0.74      0.66      1950\n\n   micro avg       0.76      0.76      0.76      6042\n   macro avg       0.73      0.75      0.74      6042\nweighted avg       0.78      0.76      0.76      6042\n\naverage_score 0.757\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "733a386ab4d0f82de8e6372c93f55f9ad71c9db6"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclf = LinearDiscriminantAnalysis()\n\nname = 'LinearDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.6592706218512671\nclassification report for LinearDiscriminantAnalysis\n              precision    recall  f1-score   support\n\n           0       0.77      0.84      0.81      4092\n           1       0.59      0.48      0.53      1950\n\n   micro avg       0.72      0.72      0.72      6042\n   macro avg       0.68      0.66      0.67      6042\nweighted avg       0.71      0.72      0.72      6042\n\naverage_score 0.724\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a15878430540793d27847ceeb537daf2c9723715"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n\nname = 'RandomForestClassifier'\n\nevaluate_classifier(clf,name) \n",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.7722294909391683\nclassification report for RandomForestClassifier\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88      4092\n           1       0.79      0.62      0.70      1950\n\n   micro avg       0.82      0.82      0.82      6042\n   macro avg       0.81      0.77      0.79      6042\nweighted avg       0.82      0.82      0.82      6042\n\naverage_score 0.825\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "828a9bfb7901e7566d722804d38214c45fb418a4"
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\n\nname = 'GaussianNB'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.5604635686893751\nclassification report for GaussianNB\n              precision    recall  f1-score   support\n\n           0       0.71      0.80      0.75      4092\n           1       0.43      0.32      0.37      1950\n\n   micro avg       0.64      0.64      0.64      6042\n   macro avg       0.57      0.56      0.56      6042\nweighted avg       0.62      0.64      0.63      6042\n\naverage_score 0.645\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3fff6b212b7aaec9dd99a6e4f65205bd4dd35338"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclf = QuadraticDiscriminantAnalysis()\n\nname = 'QuadraticDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.7381419655613204\nclassification report for QuadraticDiscriminantAnalysis\n              precision    recall  f1-score   support\n\n           0       0.81      0.96      0.88      4092\n           1       0.86      0.52      0.65      1950\n\n   micro avg       0.82      0.82      0.82      6042\n   macro avg       0.83      0.74      0.76      6042\nweighted avg       0.82      0.82      0.80      6042\n\naverage_score 0.817\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38f990e242cfa3917e51ce4607e6467ad369a27b"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import LinearSVC\n\nclf = LinearSVC()\nname = 'LinearSVC'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.549211970824874\nclassification report for LinearSVC\n              precision    recall  f1-score   support\n\n           0       0.70      0.95      0.81      4092\n           1       0.58      0.15      0.24      1950\n\n   micro avg       0.69      0.69      0.69      6042\n   macro avg       0.64      0.55      0.52      6042\nweighted avg       0.66      0.69      0.62      6042\n\naverage_score 0.691\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab29560a67ce74bdd0360140662821d75a21999d"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dropout, Dense, Flatten,BatchNormalization,LeakyReLU\nfrom keras.metrics import categorical_accuracy, binary_accuracy\nimport keras\nfrom sklearn.model_selection import train_test_split\n\n\n\nif(num_class==2):\n    \n    y = labels[:feature_tensors.shape[0]]\n    y = np.array(y)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[binary_accuracy])\n\nelse:\n    y = labels[:feature_tensors.shape[0]]\n    y = keras.utils.to_categorical(y, num_class)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[categorical_accuracy])\n\n\n\nmodel.fit(X_train,y_train,\n          epochs=12,\n          batch_size=16,\n          validation_data=(X_test, y_test)\n         )\n\nmodel.save('dense201.h5') ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 24166 samples, validate on 6042 samples\nEpoch 1/12\n24166/24166 [==============================] - 8s 320us/step - loss: 0.6089 - binary_accuracy: 0.6850 - val_loss: 0.5841 - val_binary_accuracy: 0.6789\nEpoch 2/12\n24166/24166 [==============================] - 7s 279us/step - loss: 0.5888 - binary_accuracy: 0.6923 - val_loss: 0.5767 - val_binary_accuracy: 0.6912\nEpoch 3/12\n24166/24166 [==============================] - 7s 284us/step - loss: 0.5832 - binary_accuracy: 0.6955 - val_loss: 0.5834 - val_binary_accuracy: 0.6931\nEpoch 4/12\n24166/24166 [==============================] - 7s 287us/step - loss: 0.5812 - binary_accuracy: 0.6963 - val_loss: 0.5775 - val_binary_accuracy: 0.6927\nEpoch 5/12\n24166/24166 [==============================] - 7s 280us/step - loss: 0.5764 - binary_accuracy: 0.6992 - val_loss: 0.5713 - val_binary_accuracy: 0.7031\nEpoch 6/12\n24166/24166 [==============================] - 7s 281us/step - loss: 0.5749 - binary_accuracy: 0.6999 - val_loss: 0.5733 - val_binary_accuracy: 0.6920\nEpoch 7/12\n24166/24166 [==============================] - 7s 281us/step - loss: 0.5743 - binary_accuracy: 0.7017 - val_loss: 0.5680 - val_binary_accuracy: 0.6946\nEpoch 8/12\n24166/24166 [==============================] - 7s 279us/step - loss: 0.5720 - binary_accuracy: 0.6992 - val_loss: 0.5791 - val_binary_accuracy: 0.6888\nEpoch 9/12\n24166/24166 [==============================] - 7s 280us/step - loss: 0.5705 - binary_accuracy: 0.7049 - val_loss: 0.5654 - val_binary_accuracy: 0.7041\nEpoch 10/12\n24166/24166 [==============================] - 7s 279us/step - loss: 0.5693 - binary_accuracy: 0.7043 - val_loss: 0.5640 - val_binary_accuracy: 0.6991\nEpoch 11/12\n24166/24166 [==============================] - 7s 279us/step - loss: 0.5683 - binary_accuracy: 0.7022 - val_loss: 0.5648 - val_binary_accuracy: 0.7029\nEpoch 12/12\n24166/24166 [==============================] - 7s 280us/step - loss: 0.5688 - binary_accuracy: 0.7076 - val_loss: 0.5618 - val_binary_accuracy: 0.6971\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05e365777356c5b5bc4c939544480fb6517dc798"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "roc_auc_score 0.726380805574354\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-10b77ecc8091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classification report for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \"\"\"\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f50969998d0c7f806e77b768ba88f34b0daa6db1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}