{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport random \nfrom tqdm import tqdm\n\nimport os\nimport keras\nimport pydicom\n\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef read_pickle(filename):    \n    with open(filename, 'rb') as fp:\n        return pickle.load(fp)\n    \ndef save_pickle(data,filename):       \n    with open(filename, 'wb') as fp:\n        pickle.dump(data, fp)  \n    \ndata_path = '../input/rsna-pneumonia-detection-challenge/'\n\nimages_path = data_path + 'stage_2_train_images/'\nlabels_path = data_path + 'stage_2_train_labels.csv'\n\ndetailed_class_info_path = data_path + 'stage_2_detailed_class_info.csv'\n\nclass_encoder = LabelEncoder()\n   \ndef merge_dataframes():\n    df = pd.read_csv(labels_path)\n    details_df = pd.read_csv(detailed_class_info_path)\n    df = pd.concat([df,details_df.drop('patientId',1)], 1) \n    print(df.describe())\n    print(df.shape[0], 'cases')\n\n    return df\n\n\n  \ndef load_ids_and_labels_from_file():\n    ids = read_pickle('ids')\n    labels = read_pickle('labels')\n    return ids,labels\n  \ndef get_ids_and_labels(num_class):\n    df = merge_dataframes()\n    df['class_id'] = class_encoder.fit_transform(df['class'])\n\n    df.sort_values(by=['patientId', 'class_id'])\n    \n    ids = df.patientId.tolist()\n    \n    if(num_class==2):\n        labels =  df.Target.tolist() \n    else:\n        labels =  df.class_id.tolist() \n    \n    save_pickle(ids, 'ids')\n    save_pickle(labels, 'labels')\n\n    return ids,labels\n\n      \n\nnum_class = 3\nids,labels = get_ids_and_labels(num_class)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 x            y      ...            height        Target\ncount  9555.000000  9555.000000      ...       9555.000000  30227.000000\nmean    394.047724   366.839560      ...        329.269702      0.316108\nstd     204.574172   148.940488      ...        157.750755      0.464963\nmin       2.000000     2.000000      ...         45.000000      0.000000\n25%     207.000000   249.000000      ...        203.000000      0.000000\n50%     324.000000   365.000000      ...        298.000000      0.000000\n75%     594.000000   478.500000      ...        438.000000      1.000000\nmax     835.000000   881.000000      ...        942.000000      1.000000\n\n[8 rows x 5 columns]\n30227 cases\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c3531c5aa04083c28269555a28d81f87ac7f58d"
      },
      "cell_type": "code",
      "source": "feature_tensors = np.load('../input/dense121-features/feature_vectors.npy')",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\ny = labels[:feature_tensors.shape[0]]\n# y = keras.utils.to_categorical(y, num_classes=2)\n\nX_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.1, random_state=42)\n# X_valid, X_test, y_valid, y_test  = train_test_split(X_valid, y_valid, test_size=0.4, random_state=42)",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a7d7a0ec4bee99d66ffcd3518aaeb898c6765f0"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\nimport matplotlib.pyplot as plt\n\n\ndef precision_recall(name, clf):  \n    y_pred = clf.predict(X_test)\n    \n    if(num_class==2):\n        roc_score = roc_auc_score(y_test, y_pred)\n        print('roc_auc_score', roc_score)\n\n    \n    if(num_class==3):\n        report = classification_report(y_test, y_pred, target_names=class_encoder.classes_)\n    else:\n        report = classification_report(y_test, y_pred)\n        \n    print('classification report for', name)\n    print( report )\n    \n\ndef evaluate_classifier(clf,name):    \n    clf.fit(X_train,y_train)\n\n    save_pickle(clf,name)\n\n    precision_recall(name, clf)\n    \n    score = clf.score(X_test,y_test)\n    \n    print('average_score', round(score,3))",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b237229ef5a67e0f5a110fff35936e47ed34141"
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\nname = 'DecisionTreeClassifier'\nevaluate_classifier(clf,name)     ",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for DecisionTreeClassifier\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.29      0.31      0.30       819\nNo Lung Opacity / Not Normal       0.40      0.38      0.39      1076\n                      Normal       0.28      0.29      0.29       771\n\n                   micro avg       0.33      0.33      0.33      2666\n                   macro avg       0.33      0.33      0.33      2666\n                weighted avg       0.33      0.33      0.33      2666\n\naverage_score 0.332\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "419b6baee597823824f345105828124095d75ad3"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclf = LinearDiscriminantAnalysis()\n\nname = 'LinearDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for LinearDiscriminantAnalysis\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.32      0.23      0.27       819\nNo Lung Opacity / Not Normal       0.40      0.61      0.49      1076\n                      Normal       0.27      0.16      0.20       771\n\n                   micro avg       0.36      0.36      0.36      2666\n                   macro avg       0.33      0.33      0.32      2666\n                weighted avg       0.34      0.36      0.34      2666\n\naverage_score 0.364\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34e7fbefee04cc4c5ce195556f08e02231eb4296"
      },
      "cell_type": "code",
      "source": "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclf = QuadraticDiscriminantAnalysis()\n\nname = 'QuadraticDiscriminantAnalysis'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "classification report for QuadraticDiscriminantAnalysis\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.30      0.10      0.15       819\nNo Lung Opacity / Not Normal       0.42      0.26      0.32      1076\n                      Normal       0.29      0.66      0.41       771\n\n                   micro avg       0.33      0.33      0.33      2666\n                   macro avg       0.34      0.34      0.29      2666\n                weighted avg       0.35      0.33      0.29      2666\n\naverage_score 0.325\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0b6c2ae0338c1165e6c4f78593785fcab891afb"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n\nname = 'RandomForestClassifier'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "classification report for RandomForestClassifier\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.31      0.37      0.34       819\nNo Lung Opacity / Not Normal       0.39      0.42      0.40      1076\n                      Normal       0.26      0.19      0.22       771\n\n                   micro avg       0.34      0.34      0.34      2666\n                   macro avg       0.32      0.32      0.32      2666\n                weighted avg       0.33      0.34      0.33      2666\n\naverage_score 0.336\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e14241dd18d2599699fcb65767034b07709a1c6"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import LinearSVC\n\nclf = LinearSVC()\nname = 'LinearSVC'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for LinearSVC\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.41      0.03      0.05       819\nNo Lung Opacity / Not Normal       0.30      0.02      0.04      1076\n                      Normal       0.29      0.94      0.44       771\n\n                   micro avg       0.29      0.29      0.29      2666\n                   macro avg       0.33      0.33      0.18      2666\n                weighted avg       0.33      0.29      0.16      2666\n\naverage_score 0.29\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8a0d648e79666c43ec19587e2c934f8595afb50"
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\n\nname = 'GaussianNB'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for GaussianNB\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.32      0.06      0.10       819\nNo Lung Opacity / Not Normal       0.41      0.23      0.29      1076\n                      Normal       0.29      0.73      0.42       771\n\n                   micro avg       0.32      0.32      0.32      2666\n                   macro avg       0.34      0.34      0.27      2666\n                weighted avg       0.35      0.32      0.27      2666\n\naverage_score 0.32\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e4b0b87a7cfce8fcf8b2781f0fcb9ddab3249de"
      },
      "cell_type": "code",
      "source": "from sklearn.dummy import DummyClassifier\n\nclf = DummyClassifier(strategy='stratified', random_state=0)\n\nname = 'Dummy stratified'\n\nevaluate_classifier(clf,name)\n\n\n\n\nclf = DummyClassifier(strategy='uniform', random_state=0)\n\nname = 'Dummy uniform'\n\nevaluate_classifier(clf,name) ",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": "classification report for Dummy stratified\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.29      0.30      0.30       819\nNo Lung Opacity / Not Normal       0.41      0.39      0.40      1076\n                      Normal       0.29      0.31      0.30       771\n\n                   micro avg       0.34      0.34      0.34      2666\n                   macro avg       0.33      0.33      0.33      2666\n                weighted avg       0.34      0.34      0.34      2666\n\naverage_score 0.337\nclassification report for Dummy uniform\n                              precision    recall  f1-score   support\n\n                Lung Opacity       0.34      0.36      0.35       819\nNo Lung Opacity / Not Normal       0.39      0.33      0.36      1076\n                      Normal       0.28      0.32      0.30       771\n\n                   micro avg       0.34      0.34      0.34      2666\n                   macro avg       0.34      0.34      0.34      2666\n                weighted avg       0.34      0.34      0.34      2666\n\naverage_score 0.337\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81e136bfd2f5bf14e0ae2f6bca71e99d56c316f8"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dropout, Dense, Flatten,BatchNormalization,LeakyReLU\nfrom keras.metrics import categorical_accuracy, binary_accuracy\nimport keras\nfrom sklearn.model_selection import train_test_split\n\nnum_class = 2\nids,labels = get_ids_and_labels(num_class)\n\nif(num_class==2):\n    \n    y = labels[:feature_tensors.shape[0]]\n    y = np.array(y)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[binary_accuracy])\n\nelse:\n    y = labels[:feature_tensors.shape[0]]\n    y = keras.utils.to_categorical(y, num_class)\n    X_train, X_test, y_train, y_test = train_test_split(feature_tensors, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[categorical_accuracy])\n\n\n\nmodel.fit(X_train,y_train,\n          epochs=12,\n          batch_size=16,\n          validation_data=(X_test, y_test)\n         )\n\nmodel.save('dense121.h5') ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d585033824de5343a1e89fbd2634cfa6d046b17"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "89153e36912cc3c6cc22806ce5eec915af3a6c26"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}